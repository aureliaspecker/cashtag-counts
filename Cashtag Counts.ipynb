{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "clear-product",
   "metadata": {},
   "source": [
    "## Cashtag Counts\n",
    "\n",
    "The following script reveals cashtag mentions on Twitter over time.\n",
    "\n",
    "#### Outcome \n",
    "* Results folder that contains a .csv file for each cashtag\n",
    "* Charts folder that contains a graph for each cashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "illegal-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-reservation",
   "metadata": {},
   "source": [
    "In the root directory, create a new file entitled `credentials.yaml` and populate the information (as exemplified in `credentials.yaml.template`). The credentials must be tied to Twitter's Search API (Full Archive) at enterprise access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "biblical-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./credentials.yaml') as file:\n",
    "    credentials = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "    username = credentials['enterprise_full_archive_search_credentials']['username']\n",
    "    password = credentials['enterprise_full_archive_search_credentials']['password']\n",
    "    account_name = credentials['enterprise_full_archive_search_credentials']['account_name']\n",
    "    env_label = credentials['enterprise_full_archive_search_credentials']['env_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggressive-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f'https://gnip-api.twitter.com/search/fullarchive/accounts/{account_name}/{env_label}/counts.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-cricket",
   "metadata": {},
   "source": [
    "The following cell is where you can specify the data you want to get back: \n",
    "* What stock you want to track (e.g. TWTTR) \n",
    "* What time period you'd like to pull data for (format: YYYYMMddHHmm)\n",
    "* What time bucket you want to use (options: 'day', 'hour', 'minute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thick-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'TWTR'\n",
    "fromDate = '202001010000'\n",
    "toDate = '202103040000'\n",
    "bucket = 'hour'\n",
    "\n",
    "# Only change parameters above this line \n",
    "\n",
    "body = {\n",
    "    'query': f'${stock}', \n",
    "    'fromDate': f'{fromDate}',\n",
    "    'toDate': f'{toDate}',\n",
    "    'bucket': f'{bucket}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url=endpoint, auth=(username, password), json=body)\n",
    "data = response.json()\n",
    "\n",
    "timePeriods = []\n",
    "counts = []\n",
    "if 'error' in data:\n",
    "    print(data)\n",
    "else:\n",
    "    totalCount = data['totalCount']\n",
    "    print(\"Activity count:\", totalCount)\n",
    "    for result in data['results']:\n",
    "        timePeriods.append(result['timePeriod'])\n",
    "        counts.append(result['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_count = 1\n",
    "while 'next' in data.keys():\n",
    "    next_token = data['next']\n",
    "    body.update(next=next_token)\n",
    "    try: \n",
    "        response = requests.post(url=endpoint, auth=(username, password), json=body)\n",
    "        data = response.json()\n",
    "        print(\"Activity count:\", data['totalCount'])\n",
    "        totalCount += data['totalCount']\n",
    "        for result in data['results']:\n",
    "            timePeriods.append(result['timePeriod'])\n",
    "            counts.append(result['count'])\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "    request_count += 1\n",
    "    data = response.json()\n",
    "\n",
    "print(f'Job complete: {request_count} request(s) in total')\n",
    "print('Total activity count:', totalCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Time period':timePeriods, 'Count':counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time period'] = pd.to_datetime(df['Time period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Time period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'Results/{stock}_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Time period')\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize' : 16,\n",
    "    'xtick.labelsize' : 12,\n",
    "    'ytick.labelsize' : 12,\n",
    "    'figure.figsize' : (20,10)\n",
    "}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df['Time period'], df['Count'], lw=1, ls='-', c='#1DA1F2', marker='o', ms=0)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "# For smaller datasets - display labels on x axis by day\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y')) \n",
    "# ax.xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "\n",
    "# For larger datasets - display labels on x axis by month\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%y')) \n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "\n",
    "ax.set_xlabel(\"Time period\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "plt.savefig(f'Charts/{stock}', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-crash",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
